{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset=datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader=DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset=datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader=DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter=iter(trainloader)\n",
    "images, labels=dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1=nn.Conv2d(3, 32, 5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(32, 16, 5)\n",
    "        self.fc1=nn.Linear(64*28*28, 128)\n",
    "        self.fc2=nn.Linear(120, 64)\n",
    "        self.fc3=nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x=x.view(x.shape[0], -1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        x=F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=50176, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 3, 5, 5], expected input[64, 1, 28, 28] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Abubakr\\Documents\\GitHub\\CNN-MNIST\\cnn_mnist.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=50'>51</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMean epoch loss for test: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss_mean\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=51'>52</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy on epoch: \u001b[39m\u001b[39m{\u001b[39;00mmean_acc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=53'>54</a>\u001b[0m ans\u001b[39m=\u001b[39mtorch_fit(trainloader\u001b[39m=\u001b[39;49mtrainloader, testloader\u001b[39m=\u001b[39;49mtestloader,criterion\u001b[39m=\u001b[39;49mcriterion, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, model\u001b[39m=\u001b[39;49mmodel, device\u001b[39m=\u001b[39;49mdevice)\n",
      "\u001b[1;32mc:\\Users\\Abubakr\\Documents\\GitHub\\CNN-MNIST\\cnn_mnist.ipynb Cell 8'\u001b[0m in \u001b[0;36mtorch_fit\u001b[1;34m(trainloader, testloader, criterion, lr, num_epochs, model, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=17'>18</a>\u001b[0m pred\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mforward(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=18'>19</a>\u001b[0m loss\u001b[39m=\u001b[39mcriterion(pred, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000008?line=19'>20</a>\u001b[0m train_epoch_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32mc:\\Users\\Abubakr\\Documents\\GitHub\\CNN-MNIST\\cnn_mnist.ipynb Cell 6'\u001b[0m in \u001b[0;36mNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000006?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000006?line=11'>12</a>\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000006?line=12'>13</a>\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/CNN-MNIST/cnn_mnist.ipynb#ch0000006?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Abubakr\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Abubakr\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Abubakr\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/Abubakr/Anaconda3/envs/dl/lib/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 3, 5, 5], expected input[64, 1, 28, 28] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "def torch_fit(trainloader, testloader, criterion, lr, num_epochs, model, device):\n",
    "    optimizer=optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    train_losses=[]\n",
    "    test_losses=[]\n",
    "    accuracy=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "\n",
    "        train_epoch_loss=[]\n",
    "        for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            #images.resize_(images.size()[0], 784)\n",
    "            print(images.shape)\n",
    "            optimizer.zero_grad()\n",
    "            pred=model.forward(images)\n",
    "            loss=criterion(pred, labels)\n",
    "            train_epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            test_epoch_list=[]\n",
    "            acc_on_epoch=[]\n",
    "            for j, (imagest, labelst) in enumerate(iter(testloader)):\n",
    "                imagest=imagest.to(device)\n",
    "                labelst=labelst.to(device)\n",
    "                #imagest.resize_(imagest.size()[0], 784)\n",
    "                preds=F.softmax(model(imagest), dim=1)\n",
    "                losst=criterion(preds, labelst)\n",
    "                test_epoch_list.append(losst.item())\n",
    "\n",
    "                acc_pred=preds.argmax(dim=1)\n",
    "                acc=(acc_pred == labelst).sum()/ len(labelst)\n",
    "                acc_on_epoch.append(acc.item())\n",
    "    \n",
    "        mean_acc=sum(acc_on_epoch)/len(acc_on_epoch)\n",
    "        accuracy.append(mean_acc)\n",
    "\n",
    "        test_loss_mean=sum(test_epoch_list)/len(test_epoch_list)\n",
    "        test_losses.append(test_loss_mean)\n",
    "\n",
    "        train_loss_mean=sum(train_epoch_loss)/len(train_epoch_loss)\n",
    "        train_losses.append(train_loss_mean)\n",
    "\n",
    "        print(f'Mean epoch loss for train')\n",
    "        print(f'Mean epoch loss for test: {test_loss_mean}')\n",
    "        print(f'accuracy on epoch: {mean_acc}')\n",
    "\n",
    "ans=torch_fit(trainloader=trainloader, testloader=testloader,criterion=criterion, lr=0.001, num_epochs=5, model=model, device=device)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c783155fdf7cc6e25183d446515f6b6ba379df7b28dd698d21634d1b4d5e58fd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
